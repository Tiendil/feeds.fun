[[models]]
  provider = "test"
  name = "test-model-1"
  max_context_size = 12800
  max_return_tokens = 4096
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.3'
  output_1m_tokens_cost = '0.7'

[[models]]
  provider = "test"
  name = "test-model-2"
  max_context_size = 14212
  max_return_tokens = 1024
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.7'
  output_1m_tokens_cost = '0.3'

[[models]]
  provider = "openai"
  name = "gpt-4o"
  max_context_size = 128000
  max_return_tokens = 4096
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '5'
  output_1m_tokens_cost = '15'

[[models]]
  provider = "openai"
  name = "chatgpt-4o-latest"
  max_context_size = 128000
  max_return_tokens = 16384
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '5'
  output_1m_tokens_cost = '15'

[[models]]
  provider = "openai"
  name = "gpt-4o-2024-08-06"
  max_context_size = 128000
  max_return_tokens = 16384
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '2.5'
  output_1m_tokens_cost = '10'

[[models]]
  provider = "openai"
  name = "gpt-4o-mini"
  max_context_size = 128000
  max_return_tokens = 16384
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.15'
  output_1m_tokens_cost = '0.6'

[[models]]
  provider="openai"
  name="gpt-4o-mini-2024-07-18"
  max_context_size=128000
  max_return_tokens=16384
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.15'
  output_1m_tokens_cost = '0.6'

[[models]]
  provider="google"
  name="gemini-1.5-flash-001"
  # We limit the context size to 128,000 tokens because Google increases fees after exceeding 128,000 tokens
  max_context_size=128000
  max_return_tokens=8192
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.075'
  output_1m_tokens_cost = '0.3'
