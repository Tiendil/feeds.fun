[[models]]
  provider = "test"
  name = "test-model-1"
  max_context_size = 12800
  max_return_tokens = 4096
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.3'
  output_1m_tokens_cost = '0.7'

[[models]]
  provider = "test"
  name = "test-model-2"
  max_context_size = 14212
  max_return_tokens = 1024
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.7'
  output_1m_tokens_cost = '0.3'

[[models]]
  provider = "openai"
  name = "gpt-4o"
  max_context_size = 128000
  max_return_tokens = 4096
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '5'
  output_1m_tokens_cost = '15'

[[models]]
  provider = "openai"
  name = "gpt-4o-2024-08-06"
  max_context_size = 128000
  max_return_tokens = 16384
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '2.5'
  output_1m_tokens_cost = '10'

[[models]]
  provider = "openai"
  name = "gpt-4.1"
  max_context_size = 1047576
  max_return_tokens = 32768
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '2'
  output_1m_tokens_cost = '8'

[[models]]
  provider = "openai"
  name = "gpt-4.1-2025-04-14"
  max_context_size = 1047576
  max_return_tokens = 32768
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '2'
  output_1m_tokens_cost = '8'

[[models]]
  provider = "openai"
  name = "gpt-4o-mini"
  max_context_size = 128000
  max_return_tokens = 16384
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.15'
  output_1m_tokens_cost = '0.6'

[[models]]
  provider="openai"
  name="gpt-4o-mini-2024-07-18"
  max_context_size=128000
  max_return_tokens=16384
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.15'
  output_1m_tokens_cost = '0.6'

[[models]]
  provider = "openai"
  name = "gpt-4.1-mini"
  max_context_size = 1047576
  max_return_tokens = 32768
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.4'
  output_1m_tokens_cost = '1.6'

[[models]]
  provider = "openai"
  name = "gpt-4.1-mini-2025-04-14"
  max_context_size = 1047576
  max_return_tokens = 32768
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.4'
  output_1m_tokens_cost = '1.6'

[[models]]
  provider = "openai"
  name = "gpt-4.1-nano"
  max_context_size = 1047576
  max_return_tokens = 32768
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.1'
  output_1m_tokens_cost = '0.4'

[[models]]
  provider = "openai"
  name = "gpt-4.1-nano-2025-04-14"
  max_context_size = 1047576
  max_return_tokens = 32768
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.1'
  output_1m_tokens_cost = '0.4'

[[models]]
  provider="google"
  name="gemini-2.0-flash-001"
  # We limit the context size to 128,000 tokens because Google increases fees after exceeding 128,000 tokens
  max_context_size=128000
  max_return_tokens=8192
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.10'
  output_1m_tokens_cost = '0.40'

[[models]]
  provider="google"
  name="gemini-2.0-flash-lite-001"
  # We limit the context size to 128,000 tokens because Google increases fees after exceeding 128,000 tokens
  max_context_size=128000
  max_return_tokens=8192
  max_tokens_per_entry = 300000
  input_1m_tokens_cost = '0.075'
  output_1m_tokens_cost = '0.3'
